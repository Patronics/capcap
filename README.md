Created for Hackdavis2022

uses coqui STT to create live captions for the real world.

## Inspiration
Those who are hard of hearing or deaf often struggle to communicate with others, even when they learn to lipread, it's not easy, and often difficult to understand. Many causes of hearing loss also cause an impaired sense of balance.
## What it does
Caption hat listens to the speech around its wearer, and creates real-time captions of what was said. It can also text you reminders on command. It also provides an artificial horizon to help the wearer stay balanced.
## How we built it
We used a Raspberry Pi 4, coqui.ai speech recognition, and a 24x2 character lcd to display the captions. We used the SSD1315 display and LIS3DHTR Accelerometer for the balance sensor.
## Challenges we ran into

## Accomplishments that we're proud of

## What we learned

## What's next for CaptionHat
Migrating to a more elegant form factor is a priority, probably something more like google glass. Improving the screen's resolution in the process, so we can fit more text on screen at once. 

We also want to add the ability to do real-time translation between languages, drastically increasing the benefit to many people worldwide.
